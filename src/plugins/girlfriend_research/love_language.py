"""
Love Language Analyzer
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç "—è–∑—ã–∫–∏ –ª—é–±–≤–∏" –≤ –ø–µ—Ä–µ–ø–∏—Å–∫–µ:
- –°–ª–æ–≤–∞ –æ–¥–æ–±—Ä–µ–Ω–∏—è (–∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã, –ø–æ–¥–¥–µ—Ä–∂–∫–∞)
- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è (–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á)
- –ü–æ–¥–∞—Ä–∫–∏ (–æ–±—Å—É–∂–¥–µ–Ω–∏–µ)
- –ê–∫—Ç—ã —Å–ª—É–∂–µ–Ω–∏—è (–ø–æ–º–æ—â—å, –∑–∞–±–æ—Ç–∞)
- –§–∏–∑–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–∫–æ—Å–Ω–æ–≤–µ–Ω–∏–µ (—É–ø–æ–º–∏–Ω–∞–Ω–∏—è)
"""
from collections import defaultdict, Counter
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re

# –ú–∞—Ä–∫–µ—Ä—ã —è–∑—ã–∫–æ–≤ –ª—é–±–≤–∏
WORDS_OF_AFFIRMATION = {
    # –ö–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã
    '–∫—Ä–∞—Å–∏–≤–∞—è', '–∫—Ä–∞—Å–∏–≤—ã–π', '–∫—Ä–∞—Å–æ—Ç–∫–∞', '–∫—Ä–∞—Å–∞–≤—á–∏–∫', 'gorgeous', 'beautiful', 'handsome',
    '—É–º–Ω–∏—Ü–∞', '—É–º–Ω—ã–π', '—É–º–Ω–∞—è', 'smart', '—Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π', '—Ç–∞–ª–∞–Ω—Ç–ª–∏–≤–∞—è',
    '–º–æ–ª–æ–¥–µ—Ü', 'proud', '–≥–æ—Ä–∂—É—Å—å', 'amazing', 'incredible', 'wonderful',
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞
    '–≤–µ—Ä—é –≤ —Ç–µ–±—è', '—Ç—ã —Å–ø—Ä–∞–≤–∏—à—å—Å—è', '—Ç—ã —Å–º–æ–∂–µ—à—å', '–≤—Å–µ –ø–æ–ª—É—á–∏—Ç—Å—è', '–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é',
    '—Ç—ã –ª—É—á—à–∏–π', '—Ç—ã –ª—É—á—à–∞—è', '—Ç—ã –æ—Å–æ–±–µ–Ω–Ω—ã–π', '—Ç—ã –æ—Å–æ–±–µ–Ω–Ω–∞—è',
    # –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å
    '—Å–ø–∞—Å–∏–±–æ', '–±–ª–∞–≥–æ–¥–∞—Ä—é', '—Ü–µ–Ω—é', 'appreciate', 'grateful',
    # –í—ã—Ä–∞–∂–µ–Ω–∏–µ —á—É–≤—Å—Ç–≤
    '–ª—é–±–ª—é', '–æ–±–æ–∂–∞—é', '–Ω—Ä–∞–≤–∏—à—å—Å—è', 'love', 'adore', '—Å–∫—É—á–∞—é', 'miss you',
}

QUALITY_TIME = {
    # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á
    '–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—Ç–∏–º—Å—è', '—Ö–æ—á—É —É–≤–∏–¥–µ—Ç—å', '–∫–æ–≥–¥–∞ —É–≤–∏–¥–∏–º—Å—è', '—Å–∫–æ—Ä–æ —É–≤–∏–¥–∏–º—Å—è',
    '–ø–æ–π–¥—ë–º', '–ø–æ–π–¥–µ–º', '—Å—Ö–æ–¥–∏–º', '–ø–æ–µ—Ö–∞–ª–∏', '–ø–æ–µ–¥–µ–º',
    # –ú–µ—Å—Ç–∞
    '—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–∏–Ω–æ', '–∫–∞—Ñ–µ', '–ø–∞—Ä–∫', '–ø—Ä–æ–≥—É–ª–∫–∞', '–ø–æ–≥—É–ª—è—Ç—å', '–≥—É–ª—è—Ç—å',
    '–≤–º–µ—Å—Ç–µ', 'together', '–≤–¥–≤–æ—ë–º', '–≤–¥–≤–æ–µ–º',
    # –í—Ä–µ–º—è
    '–≤—ã—Ö–æ–¥–Ω—ã–µ', 'weekend', '–≤–µ—á–µ—Ä', 'evening', '—Å–≤–∏–¥–∞–Ω–∏–µ', 'date',
    '–ø—Ä–æ–≤–µ–¥—ë–º –≤—Ä–µ–º—è', '–ø—Ä–æ–≤–µ–¥–µ–º –≤—Ä–µ–º—è', '–≤—Ä–µ–º—è –≤–º–µ—Å—Ç–µ',
}

ACTS_OF_SERVICE = {
    # –ü–æ–º–æ—â—å
    '–ø–æ–º–æ–≥—É', '–ø–æ–º–æ—á—å', '–ø–æ–º–æ—â—å', 'help', '—Å–¥–µ–ª–∞—é –¥–ª—è —Ç–µ–±—è',
    '–ø—Ä–∏–≥–æ—Ç–æ–≤–ª—é', '–≥–æ—Ç–æ–≤–ª—é', 'cook', '—É–±–µ—Ä—É', 'clean',
    # –ó–∞–±–æ—Ç–∞
    '–ø–æ–∑–∞–±–æ—á—É—Å—å', '–∑–∞–±–æ—á—É—Å—å', 'care', '–ø—Ä–∏–Ω–µ—Å—É', '–ø—Ä–∏–≤–µ–∑—É', '–∫—É–ø–ª—é',
    '–æ—Ç–≤–µ–∑—É', '–≤—Å—Ç—Ä–µ—á—É', '–ø—Ä–æ–≤–æ–∂—É',
    # –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
    '—Ä–∞–∑–±–µ—Ä—É—Å—å', '—Ä–µ—à—É', '–∑–∞–π–º—É—Å—å', '—Å–¥–µ–ª–∞—é',
    '–Ω–µ –±–µ—Å–ø–æ–∫–æ–π—Å—è', '–Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–π', '—è —Ä–∞–∑–±–µ—Ä—É—Å—å',
}

GIFTS = {
    # –ü–æ–¥–∞—Ä–∫–∏
    '–ø–æ–¥–∞—Ä–æ–∫', 'gift', 'present', '—Å—é—Ä–ø—Ä–∏–∑', 'surprise',
    # –ü–æ–∫—É–ø–∫–∏
    '–∫—É–ø–∏–ª', '–∫—É–ø–∏–ª–∞', '–∫—É–ø–ª—é', 'bought', 'buy',
    '–∑–∞–∫–∞–∑–∞–ª', '–∑–∞–∫–∞–∑–∞–ª–∞', 'order',
    # –¶–≤–µ—Ç—ã
    '—Ü–≤–µ—Ç—ã', 'flowers', '–±—É–∫–µ—Ç', 'roses', '—Ä–æ–∑—ã',
}

PHYSICAL_TOUCH = {
    # –û–±—ä—è—Ç–∏—è
    '–æ–±–Ω–∏–º–∞—é', '–æ–±–Ω—è—Ç—å', 'hug', '–æ–±–Ω–∏–º–∞—à–∫–∏', 'cuddle',
    # –ü–æ—Ü–µ–ª—É–∏
    '—Ü–µ–ª—É—é', '–ø–æ—Ü–µ–ª—É–π', 'kiss', '—á–º–æ–∫',
    # –ë–ª–∏–∑–æ—Å—Ç—å
    '–ø—Ä–∏–∂–∞—Ç—å—Å—è', '–ø—Ä–∏–∂–º—É—Å—å', '—Ä—è–¥–æ–º', '–±–ª–∏–∑–∫–æ', '—Ç–µ–ø–ª–æ',
    '—Ä—É–∫—É', '–¥–µ—Ä–∂–∞—Ç—å –∑–∞ —Ä—É–∫—É', 'hold hands',
    # –ù–µ–∂–Ω–æ—Å—Ç—å
    '–ø–æ–≥–ª–∞–¥–∏—Ç—å', '–≥–ª–∞–¥–∏—Ç—å', '–º–∞—Å—Å–∞–∂', 'massage',
}


def extract_text(msg):
    text = msg.get("text", "")
    if isinstance(text, list):
        parts = []
        for part in text:
            if isinstance(part, str):
                parts.append(part)
            elif isinstance(part, dict):
                parts.append(part.get("text", ""))
        return " ".join(parts)
    return str(text)


def count_markers(text, markers):
    text_lower = text.lower()
    count = 0
    for marker in markers:
        if marker in text_lower:
            count += 1
    return count


def run_plugin(data):
    messages = data.get("messages", [])
    chat_name = data.get("name", "Chat")
    
    if not messages:
        st.warning("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return
    
    st.subheader(f"üíï –Ø–∑—ã–∫–∏ –ª—é–±–≤–∏ ‚Äî {chat_name}")
    
    st.markdown("""
    –ö–æ–Ω—Ü–µ–ø—Ü–∏—è "5 —è–∑—ã–∫–æ–≤ –ª—é–±–≤–∏" –ì—ç—Ä–∏ –ß–µ–ø–º–µ–Ω–∞:
    - üí¨ **–°–ª–æ–≤–∞ –æ–¥–æ–±—Ä–µ–Ω–∏—è** ‚Äî –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã, –ø–æ–¥–¥–µ—Ä–∂–∫–∞, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å
    - ‚è∞ **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è** ‚Äî –∂–µ–ª–∞–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤—Ä–µ–º—è –≤–º–µ—Å—Ç–µ
    - üéÅ **–ü–æ–¥–∞—Ä–∫–∏** ‚Äî –¥–∞—Ä–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥–∞—Ä–∫–æ–≤
    - üõ†Ô∏è **–ê–∫—Ç—ã —Å–ª—É–∂–µ–Ω–∏—è** ‚Äî –ø–æ–º–æ—â—å, –∑–∞–±–æ—Ç–∞, —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
    - ü§ó **–§–∏–∑–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–∫–æ—Å–Ω–æ–≤–µ–Ω–∏–µ** ‚Äî –æ–±—ä—è—Ç–∏—è, –ø–æ—Ü–µ–ª—É–∏, –Ω–µ–∂–Ω–æ—Å—Ç—å
    """)
    
    # –°—á–∏—Ç–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_languages = defaultdict(lambda: {
        "words": 0,
        "time": 0,
        "gifts": 0,
        "service": 0,
        "touch": 0,
    })
    
    for msg in messages:
        sender = msg.get("from")
        if not sender:
            continue
        
        text = extract_text(msg)
        if not text.strip():
            continue
        
        user_languages[sender]["words"] += count_markers(text, WORDS_OF_AFFIRMATION)
        user_languages[sender]["time"] += count_markers(text, QUALITY_TIME)
        user_languages[sender]["gifts"] += count_markers(text, GIFTS)
        user_languages[sender]["service"] += count_markers(text, ACTS_OF_SERVICE)
        user_languages[sender]["touch"] += count_markers(text, PHYSICAL_TOUCH)
    
    if not user_languages:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è.")
        return
    
    participants = sorted(user_languages.keys())
    
    # –¢–∞–±–ª–∏—Ü–∞
    language_names = {
        "words": "üí¨ –°–ª–æ–≤–∞ –æ–¥–æ–±—Ä–µ–Ω–∏—è",
        "time": "‚è∞ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è",
        "gifts": "üéÅ –ü–æ–¥–∞—Ä–∫–∏",
        "service": "üõ†Ô∏è –ê–∫—Ç—ã —Å–ª—É–∂–µ–Ω–∏—è",
        "touch": "ü§ó –ü—Ä–∏–∫–æ—Å–Ω–æ–≤–µ–Ω–∏—è",
    }
    
    data_rows = []
    for user in participants:
        row = {"–£—á–∞—Å—Ç–Ω–∏–∫": user}
        langs = user_languages[user]
        for key, name in language_names.items():
            row[name] = langs[key]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫
        if any(langs.values()):
            primary = max(langs.keys(), key=lambda k: langs[k])
            row["–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫"] = language_names[primary]
        else:
            row["–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫"] = "‚Äî"
        
        data_rows.append(row)
    
    df = pd.DataFrame(data_rows)
    st.dataframe(df, hide_index=True)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if len(participants) >= 2:
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # Radar chart –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–ø—Ä–æ—â—ë–Ω–Ω–æ —á–µ—Ä–µ–∑ bar)
        categories = list(language_names.values())
        x = np.arange(len(categories))
        width = 0.35
        
        colors = ['#2196F3', '#FF9800']
        
        for i, user in enumerate(participants[:2]):
            langs = user_languages[user]
            values = [langs[k] for k in language_names.keys()]
            offset = width * (i - 0.5)
            axes[0].bar(x + offset, values, width, label=user, color=colors[i], alpha=0.7)
        
        axes[0].set_xticks(x)
        axes[0].set_xticklabels([name.split()[1] for name in categories], rotation=45, ha='right')
        axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Ä–∫–µ—Ä–æ–≤')
        axes[0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤ –ª—é–±–≤–∏')
        axes[0].legend()
        
        # Pie charts –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞
        for i, user in enumerate(participants[:2]):
            langs = user_languages[user]
            values = [langs[k] for k in language_names.keys()]
            
            if sum(values) > 0:
                # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                wedges, texts, autotexts = axes[1].pie(
                    values if i == 0 else [],  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ
                    labels=[name.split()[0] for name in categories] if i == 0 else None,
                    autopct='%1.0f%%' if i == 0 else None,
                    startangle=90,
                )
        
        axes[1].set_title(f'–ü—Ä–æ—Ñ–∏–ª—å —è–∑—ã–∫–æ–≤: {participants[0]}' if participants else '–ü—Ä–æ—Ñ–∏–ª—å')
        
        plt.tight_layout()
        st.pyplot(fig)
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    st.markdown("### üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    
    for user in participants:
        langs = user_languages[user]
        total = sum(langs.values())
        
        if total == 0:
            st.info(f"**{user}**: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–æ–≤ –ª—é–±–≤–∏.")
            continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        sorted_langs = sorted(langs.items(), key=lambda x: x[1], reverse=True)
        
        st.markdown(f"**{user}**:")
        for lang_key, count in sorted_langs:
            percentage = count / total * 100 if total > 0 else 0
            bar_length = int(percentage / 5)  # –í–∏–∑—É–∞–ª—å–Ω–∞—è —à–∫–∞–ª–∞
            bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
            st.write(f"  {language_names[lang_key]}: {bar} {count} ({percentage:.0f}%)")
    
    # –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    if len(participants) >= 2:
        st.markdown("### üíû –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —è–∑—ã–∫–æ–≤ –ª—é–±–≤–∏")
        
        user1_langs = user_languages[participants[0]]
        user2_langs = user_languages[participants[1]]
        
        # –ù–∞—Ö–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ —è–∑—ã–∫–∏ –∫–∞–∂–¥–æ–≥–æ
        if sum(user1_langs.values()) > 0 and sum(user2_langs.values()) > 0:
            primary1 = max(user1_langs.keys(), key=lambda k: user1_langs[k])
            primary2 = max(user2_langs.keys(), key=lambda k: user2_langs[k])
            
            if primary1 == primary2:
                st.success(f"""
                ‚úÖ **–û—Ç–ª–∏—á–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å!**
                
                –û–±–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç –æ–¥–∏–Ω —è–∑—ã–∫ –ª—é–±–≤–∏: **{language_names[primary1]}**
                
                –≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –≤—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–Ω–∏–º–∞–µ—Ç–µ –¥—Ä—É–≥ –¥—Ä—É–≥–∞ –∏ –º–æ–∂–µ—Ç–µ –ª–µ–≥–∫–æ
                –≤—ã—Ä–∞–∂–∞—Ç—å –ª—é–±–æ–≤—å —Å–ø–æ—Å–æ–±–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω—è—Ç–µ–Ω –ø–∞—Ä—Ç–Ω—ë—Ä—É.
                """)
            else:
                st.info(f"""
                ‚ÑπÔ∏è **–†–∞–∑–Ω—ã–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —è–∑—ã–∫–∏:**
                
                - **{participants[0]}**: {language_names[primary1]}
                - **{participants[1]}**: {language_names[primary2]}
                
                –≠—Ç–æ –Ω–µ –ø–ª–æ—Ö–æ! –ü—Ä–æ—Å—Ç–æ –≤–∞–∂–Ω–æ –æ—Å–æ–∑–Ω–∞–≤–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –∏ —Å—Ç–∞—Ä–∞—Ç—å—Å—è "–ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å" 
                —Å–≤–æ—é –ª—é–±–æ–≤—å –Ω–∞ —è–∑—ã–∫ –ø–∞—Ä—Ç–Ω—ë—Ä–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø–∞—Ä—Ç–Ω—ë—Ä —Ü–µ–Ω–∏—Ç 
                {language_names[primary2].split()[1].lower()}, —Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å –±–æ–ª—å—à–µ —ç—Ç–æ –≤—ã—Ä–∞–∂–∞—Ç—å.
                """)


import numpy as np

