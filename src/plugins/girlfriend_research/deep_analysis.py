"""
Deep Relationship Analysis
–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–Ω–æ—à–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ NLP.
–£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è, n-–≥—Ä–∞–º–º—ã.
"""
from collections import defaultdict
from datetime import datetime
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, os.path.dirname(__file__))

try:
    from text_analyzer import RelationshipAnalyzer, SentimentAnalyzer
except ImportError:
    # Fallback –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    RelationshipAnalyzer = None
    SentimentAnalyzer = None


def get_text(msg):
    text = msg.get('text', '')
    if isinstance(text, list):
        parts = []
        for part in text:
            if isinstance(part, str):
                parts.append(part)
            elif isinstance(part, dict) and 'text' in part:
                parts.append(part['text'])
        return ' '.join(parts)
    return str(text) if text else ''


def parse_date(date_str):
    return datetime.strptime(date_str, "%Y-%m-%dT%H:%M:%S")


def run_plugin(data):
    messages = data.get("messages", [])
    chat_name = data.get("name", "Chat")
    
    if not messages:
        st.warning("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return
    
    st.subheader(f"üî¨ –ì–ª—É–±–æ–∫–∏–π –ê–Ω–∞–ª–∏–∑ ‚Äî {chat_name}")
    st.markdown("""
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ n-–≥—Ä–∞–º–º.
    –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    """)
    
    if RelationshipAnalyzer is None:
        st.error("–ú–æ–¥—É–ª—å text_analyzer –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞–∑–æ–≤—ã–µ –ø–ª–∞–≥–∏–Ω—ã.")
        return
    
    analyzer = RelationshipAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    user_analysis = defaultdict(lambda: {
        'messages': 0,
        'chars': 0,
        'sentiment_scores': [],
        'insecurity': defaultdict(list),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä—ã
        'control': defaultdict(list),
        'support': defaultdict(list),
    })
    
    monthly_sentiment = defaultdict(lambda: defaultdict(list))
    
    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è..."):
        for msg in messages:
            sender = msg.get('from')
            if not sender:
                continue
            
            text = get_text(msg)
            if not text or len(text) < 3:
                continue
            
            user_analysis[sender]['messages'] += 1
            user_analysis[sender]['chars'] += len(text)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            result = analyzer.analyze_message(text)
            
            # Sentiment
            if result['sentiment']['confidence'] > 0.2:
                user_analysis[sender]['sentiment_scores'].append(result['sentiment']['score'])
                
                try:
                    dt = parse_date(msg['date'])
                    month = dt.strftime('%Y-%m')
                    monthly_sentiment[month][sender].append(result['sentiment']['score'])
                except:
                    pass
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            for category, matches in result['insecurity'].items():
                for pattern, context in matches:
                    if len(user_analysis[sender]['insecurity'][category]) < 5:
                        user_analysis[sender]['insecurity'][category].append({
                            'pattern': pattern,
                            'context': context,
                            'text': text[:100]
                        })
            
            for category, matches in result['control'].items():
                for pattern, context in matches:
                    if len(user_analysis[sender]['control'][category]) < 5:
                        user_analysis[sender]['control'][category].append({
                            'pattern': pattern,
                            'context': context,
                            'text': text[:100]
                        })
            
            for category, matches in result['support'].items():
                for pattern, context in matches:
                    if len(user_analysis[sender]['support'][category]) < 5:
                        user_analysis[sender]['support'][category].append({
                            'pattern': pattern,
                            'context': context,
                            'text': text[:100]
                        })
    
    users = list(user_analysis.keys())
    
    if not users:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è.")
        return
    
    # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.markdown("### üìä –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å")
    
    table_data = []
    for user in users:
        stats = user_analysis[user]
        scores = stats['sentiment_scores']
        
        if scores:
            avg_sentiment = sum(scores) / len(scores)
            positive_pct = sum(1 for s in scores if s > 0.2) / len(scores) * 100
            negative_pct = sum(1 for s in scores if s < -0.2) / len(scores) * 100
            neutral_pct = 100 - positive_pct - negative_pct
        else:
            avg_sentiment = 0
            positive_pct = negative_pct = neutral_pct = 0
        
        # –°—á–∏—Ç–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        total_insecurity = sum(len(v) for v in stats['insecurity'].values())
        total_control = sum(len(v) for v in stats['control'].values())
        total_support = sum(len(v) for v in stats['support'].values())
        
        table_data.append({
            '–£—á–∞—Å—Ç–Ω–∏–∫': user,
            '–°–æ–æ–±—â–µ–Ω–∏–π': stats['messages'],
            'üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö': f"{positive_pct:.0f}%",
            'üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö': f"{neutral_pct:.0f}%",
            'üò¢ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö': f"{negative_pct:.0f}%",
            '–°—Ä. –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ': f"{avg_sentiment:+.2f}",
            'üò∞ –ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': total_insecurity,
            'üéØ –ö–æ–Ω—Ç—Ä–æ–ª—å': total_control,
            'ü§ù –ü–æ–¥–¥–µ—Ä–∂–∫–∞': total_support,
        })
    
    df = pd.DataFrame(table_data)
    st.dataframe(df, hide_index=True)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
    st.markdown("### üìà –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ –º–µ—Å—è—Ü–∞–º")
    
    if len(monthly_sentiment) > 1:
        months = sorted(monthly_sentiment.keys())
        
        fig, ax = plt.subplots(figsize=(12, 5))
        
        for user in users:
            avg_by_month = []
            for month in months:
                scores = monthly_sentiment[month].get(user, [])
                avg = sum(scores) / len(scores) if scores else None
                avg_by_month.append(avg)
            
            ax.plot(months, avg_by_month, marker='o', label=user, linewidth=2)
        
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        ax.set_xlabel('–ú–µ—Å—è—Ü')
        ax.set_ylabel('–°—Ä–µ–¥–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ (-1 –¥–æ +1)')
        ax.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–æ–Ω–∞')
        ax.legend()
        ax.tick_params(axis='x', rotation=45)
        ax.set_ylim(-1, 1)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    st.markdown("### üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
    
    for user in users:
        stats = user_analysis[user]
        
        with st.expander(f"üë§ {user}"):
            # –ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            if any(stats['insecurity'].values()):
                st.markdown("#### üò∞ –ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–±–µ")
                for category, examples in stats['insecurity'].items():
                    if examples:
                        st.markdown(f"**{category.replace('_', ' ').title()}** ({len(examples)} —Å–ª—É—á–∞–µ–≤)")
                        for ex in examples[:3]:
                            st.caption(f"¬´_{ex['text']}..._¬ª ‚Äî –ø–∞—Ç—Ç–µ—Ä–Ω: **{ex['pattern']}**")
            else:
                st.success("‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            
            st.divider()
            
            # –ö–æ–Ω—Ç—Ä–æ–ª—å
            if any(stats['control'].values()):
                st.markdown("#### üéØ –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ")
                for category, examples in stats['control'].items():
                    if examples:
                        st.markdown(f"**{category.replace('_', ' ').title()}** ({len(examples)} —Å–ª—É—á–∞–µ–≤)")
                        for ex in examples[:3]:
                            st.caption(f"¬´_{ex['text']}..._¬ª ‚Äî –ø–∞—Ç—Ç–µ—Ä–Ω: **{ex['pattern']}**")
            else:
                st.success("‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            
            st.divider()
            
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞
            if any(stats['support'].values()):
                st.markdown("#### ü§ù –ü–æ–¥–¥–µ—Ä–∂–∫–∞")
                for category, examples in stats['support'].items():
                    if examples:
                        st.markdown(f"**{category.replace('_', ' ').title()}** ({len(examples)} —Å–ª—É—á–∞–µ–≤)")
                        for ex in examples[:3]:
                            st.caption(f"¬´_{ex['text']}..._¬ª")
            else:
                st.info("üìù –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    if len(users) >= 2:
        st.markdown("### ‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        user1, user2 = users[0], users[1]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"**{user1}**")
            stats1 = user_analysis[user1]
            avg1 = sum(stats1['sentiment_scores']) / len(stats1['sentiment_scores']) if stats1['sentiment_scores'] else 0
            
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ", f"{avg1:+.2f}")
            st.metric("–ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", sum(len(v) for v in stats1['insecurity'].values()))
            st.metric("–ö–æ–Ω—Ç—Ä–æ–ª—å", sum(len(v) for v in stats1['control'].values()))
            st.metric("–ü–æ–¥–¥–µ—Ä–∂–∫–∞", sum(len(v) for v in stats1['support'].values()))
        
        with col2:
            st.markdown(f"**{user2}**")
            stats2 = user_analysis[user2]
            avg2 = sum(stats2['sentiment_scores']) / len(stats2['sentiment_scores']) if stats2['sentiment_scores'] else 0
            
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ", f"{avg2:+.2f}")
            st.metric("–ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", sum(len(v) for v in stats2['insecurity'].values()))
            st.metric("–ö–æ–Ω—Ç—Ä–æ–ª—å", sum(len(v) for v in stats2['control'].values()))
            st.metric("–ü–æ–¥–¥–µ—Ä–∂–∫–∞", sum(len(v) for v in stats2['support'].values()))
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
    st.markdown("### üí° –í—ã–≤–æ–¥—ã")
    
    for user in users:
        stats = user_analysis[user]
        avg_sentiment = sum(stats['sentiment_scores']) / len(stats['sentiment_scores']) if stats['sentiment_scores'] else 0
        
        total_insecurity = sum(len(v) for v in stats['insecurity'].values())
        total_control = sum(len(v) for v in stats['control'].values())
        total_support = sum(len(v) for v in stats['support'].values())
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ 100 —Å–æ–æ–±—â–µ–Ω–∏–π
        msg_count = stats['messages']
        ins_per_100 = total_insecurity / msg_count * 100 if msg_count > 0 else 0
        ctrl_per_100 = total_control / msg_count * 100 if msg_count > 0 else 0
        sup_per_100 = total_support / msg_count * 100 if msg_count > 0 else 0
        
        issues = []
        
        if avg_sentiment < -0.2:
            issues.append("–ø—Ä–µ–æ–±–ª–∞–¥–∞–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ")
        if ins_per_100 > 2:
            issues.append("–ø–æ–≤—ã—à–µ–Ω–Ω–∞—è –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–±–µ")
        if ctrl_per_100 > 1:
            issues.append("–ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è")
        
        positives = []
        if avg_sentiment > 0.2:
            positives.append("–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ñ–æ–Ω")
        if sup_per_100 > 3:
            positives.append("–≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏")
        
        if issues:
            st.warning(f"**{user}**: ‚ö†Ô∏è {', '.join(issues)}")
        
        if positives:
            st.success(f"**{user}**: ‚úÖ {', '.join(positives)}")
        
        if not issues and not positives:
            st.info(f"**{user}**: üìä –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å")
    
    st.markdown("---")
    st.caption("""
    **–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è**: –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è, 
    —É—á—ë—Ç –æ—Ç—Ä–∏—Ü–∞–Ω–∏–π ("–Ω–µ –ª—é–±–ª—é" = –Ω–µ–≥–∞—Ç–∏–≤), –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–∑.
    –¢–æ—á–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –Ω–æ –≤—Å—ë –µ—â—ë –Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç 
    –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É.
    """)

