"""
Text Analyzer - –æ–±—â–∏–π –º–æ–¥—É–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–∏–º–∏ –ø–ª–∞–≥–∏–Ω–∞–º–∏ girlfriend_research.

–£–ª—É—á—à–µ–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–æ—Å—Ç—ã–º –ø–æ–∏—Å–∫–æ–º –º–∞—Ä–∫–µ—Ä–æ–≤:
1. N-–≥—Ä–∞–º–º—ã (—Ñ—Ä–∞–∑—ã –∏–∑ 2-3 —Å–ª–æ–≤)
2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—á—Ç–æ –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞)
3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
4. –£—á—ë—Ç –æ—Ç—Ä–∏—Ü–∞–Ω–∏–π ("–Ω–µ –ª—é–±–ª—é" vs "–ª—é–±–ª—é")
5. –≠–º–æ–¥–∑–∏-–∞–Ω–∞–ª–∏–∑
"""
import re
from collections import Counter, defaultdict
from typing import List, Dict, Tuple, Set, Optional


def normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã"""
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def extract_words(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –Ω–µ-–±—É–∫–≤–∞–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–æ–¥–∑–∏
    words = re.findall(r'[\w]+|[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', text.lower())
    return words


def get_ngrams(words: List[str], n: int) -> List[str]:
    """–°–æ–∑–¥–∞—ë—Ç n-–≥—Ä–∞–º–º—ã –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤"""
    if len(words) < n:
        return []
    return [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]


def check_negation(text: str, keyword: str, window: int = 3) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º"""
    negations = {'–Ω–µ', '–Ω–µ—Ç', '–Ω–∏', '–Ω–∏–∫–æ–≥–¥–∞', '–±–µ–∑', 'never', 'not', "don't", "doesn't", "didn't"}
    
    words = extract_words(text)
    try:
        idx = words.index(keyword)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–¥ –∫–ª—é—á–µ–≤—ã–º
        start = max(0, idx - window)
        context = words[start:idx]
        return any(neg in context for neg in negations)
    except ValueError:
        return False


class SentimentAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ —Å –≤–µ—Å–∞–º–∏
    POSITIVE_WORDS = {
        # –°–∏–ª—å–Ω—ã–π –ø–æ–∑–∏—Ç–∏–≤ (–≤–µ—Å 2)
        '–ª—é–±–ª—é': 2, '–æ–±–æ–∂–∞—é': 2, '—Å—á–∞—Å—Ç–ª–∏–≤': 2, '—Å—á–∞—Å—Ç–ª–∏–≤–∞': 2, '–≤–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–æ': 2,
        '–ø–æ—Ç—Ä—è—Å–∞—é—â–µ': 2, '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ': 2, '–∏–¥–µ–∞–ª—å–Ω–æ': 2, '–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ': 2,
        'love': 2, 'amazing': 2, 'wonderful': 2, 'perfect': 2, 'incredible': 2,
        
        # –°—Ä–µ–¥–Ω–∏–π –ø–æ–∑–∏—Ç–∏–≤ (–≤–µ—Å 1)
        '—Ö–æ—Ä–æ—à–æ': 1, '–æ—Ç–ª–∏—á–Ω–æ': 1, '–∫—Ä—É—Ç–æ': 1, '–∫–ª–∞—Å—Å–Ω–æ': 1, '–∑–¥–æ—Ä–æ–≤–æ': 1,
        '–Ω—Ä–∞–≤–∏—Ç—Å—è': 1, '—Ä–∞–¥': 1, '—Ä–∞–¥–∞': 1, '–¥–æ–≤–æ–ª–µ–Ω': 1, '–¥–æ–≤–æ–ª—å–Ω–∞': 1,
        '—Å–ø–∞—Å–∏–±–æ': 1, '–±–ª–∞–≥–æ–¥–∞—Ä—é': 1, '–º–æ–ª–æ–¥–µ—Ü': 1, '—É–º–Ω–∏—Ü–∞': 1,
        'great': 1, 'good': 1, 'nice': 1, 'happy': 1, 'glad': 1, 'thanks': 1,
        
        # –°–ª–∞–±—ã–π –ø–æ–∑–∏—Ç–∏–≤ (–≤–µ—Å 0.5)
        '–Ω–æ—Ä–º': 0.5, '–æ–∫': 0.5, '–æ–∫–µ–π': 0.5, '–Ω–µ–ø–ª–æ—Ö–æ': 0.5, '—Å–æ–π–¥—ë—Ç': 0.5,
        'okay': 0.5, 'fine': 0.5, 'alright': 0.5,
    }
    
    NEGATIVE_WORDS = {
        # –°–∏–ª—å–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤ (–≤–µ—Å 2)
        '–Ω–µ–Ω–∞–≤–∏–∂—É': 2, '–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ': 2, '—É–∂–∞—Å–Ω–æ': 2, '–∫–æ—à–º–∞—Ä': 2,
        'hate': 2, 'terrible': 2, 'horrible': 2, 'awful': 2,
        
        # –°—Ä–µ–¥–Ω–∏–π –Ω–µ–≥–∞—Ç–∏–≤ (–≤–µ—Å 1)
        '–ø–ª–æ—Ö–æ': 1, '–≥—Ä—É—Å—Ç–Ω–æ': 1, '–æ–±–∏–¥–Ω–æ': 1, '—Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω': 1, '—Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞': 1,
        '–∑–ª—é—Å—å': 1, '–±–µ—Å–∏—Ç': 1, '—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç': 1, '–¥–æ—Å—Ç–∞–ª–æ': 1, '–Ω–∞–¥–æ–µ–ª–æ': 1,
        '—É—Å—Ç–∞–ª': 1, '—É—Å—Ç–∞–ª–∞': 1, '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω': 1, '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∞': 1,
        'sad': 1, 'angry': 1, 'upset': 1, 'annoyed': 1, 'tired': 1, 'bad': 1,
        
        # –°–ª–∞–±—ã–π –Ω–µ–≥–∞—Ç–∏–≤ (–≤–µ—Å 0.5)
        '–Ω–µ –æ—á–µ–Ω—å': 0.5, '—Ç–∞–∫ —Å–µ–±–µ': 0.5, '–º–æ–≥–ª–æ –±—ã—Ç—å –ª—É—á—à–µ': 0.5,
        'not great': 0.5, 'meh': 0.5,
    }
    
    POSITIVE_EMOJIS = {
        'üòä': 1, 'üòÑ': 1, 'üòÉ': 1, 'üòÅ': 1, 'üôÇ': 0.5, 'üòç': 2, 'ü•∞': 2,
        '‚ù§Ô∏è': 1.5, 'üíï': 1.5, 'üíñ': 1.5, 'üíó': 1, 'üíì': 1, 'üíò': 1.5,
        'üòò': 1.5, 'üòö': 1, 'üòª': 1.5, 'ü§ó': 1, 'ü•≥': 1.5, 'üéâ': 1,
        'üëç': 0.5, 'üëè': 1, 'üôè': 0.5, '‚ú®': 0.5, 'üåü': 0.5, 'üí™': 0.5,
    }
    
    NEGATIVE_EMOJIS = {
        'üò¢': 1, 'üò≠': 1.5, 'üòû': 1, 'üòî': 1, 'üòü': 1, 'üòï': 0.5,
        'üò§': 1, 'üò†': 1.5, 'üò°': 2, 'ü§¨': 2, 'üíî': 1.5, 'üòí': 1,
        'üôÑ': 0.5, 'üòë': 0.5, 'üò©': 1, 'üò´': 1, 'üò£': 1, 'üòñ': 1,
    }
    
    def analyze(self, text: str) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è.
        
        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏:
            - score: float –æ—Ç -1 –¥–æ 1 (-1 = –æ—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ, 1 = –æ—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ)
            - positive_words: list –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤
            - negative_words: list –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤
            - confidence: float –æ—Ç 0 –¥–æ 1 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ü–µ–Ω–∫–µ)
        """
        text_lower = normalize_text(text)
        words = extract_words(text)
        
        positive_score = 0.0
        negative_score = 0.0
        positive_found = []
        negative_found = []
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–≤
        for word in words:
            if word in self.POSITIVE_WORDS:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ
                if check_negation(text_lower, word):
                    negative_score += self.POSITIVE_WORDS[word]
                    negative_found.append(f"–Ω–µ {word}")
                else:
                    positive_score += self.POSITIVE_WORDS[word]
                    positive_found.append(word)
            
            if word in self.NEGATIVE_WORDS:
                if check_negation(text_lower, word):
                    positive_score += self.NEGATIVE_WORDS[word] * 0.5  # –î–≤–æ–π–Ω–æ–µ –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ —Å–ª–∞–±–µ–µ
                    positive_found.append(f"–Ω–µ {word}")
                else:
                    negative_score += self.NEGATIVE_WORDS[word]
                    negative_found.append(word)
        
        # –ê–Ω–∞–ª–∏–∑ —ç–º–æ–¥–∑–∏
        for char in text:
            if char in self.POSITIVE_EMOJIS:
                positive_score += self.POSITIVE_EMOJIS[char]
                positive_found.append(char)
            if char in self.NEGATIVE_EMOJIS:
                negative_score += self.NEGATIVE_EMOJIS[char]
                negative_found.append(char)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π score
        total = positive_score + negative_score
        if total == 0:
            score = 0.0
            confidence = 0.0
        else:
            score = (positive_score - negative_score) / total
            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
            confidence = min(1.0, total / 5)
        
        return {
            'score': score,
            'positive_words': positive_found,
            'negative_words': negative_found,
            'positive_score': positive_score,
            'negative_score': negative_score,
            'confidence': confidence,
        }


class PatternMatcher:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    
    def __init__(self, patterns: Dict[str, Set[str]]):
        """
        patterns: Dict –∫–∞—Ç–µ–≥–æ—Ä–∏—è -> –Ω–∞–±–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        self.patterns = patterns
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã
        self.single_words = {}
        self.phrases = {}
        
        for category, pattern_set in patterns.items():
            self.single_words[category] = set()
            self.phrases[category] = set()
            
            for p in pattern_set:
                if ' ' in p:
                    self.phrases[category].add(p.lower())
                else:
                    self.single_words[category].add(p.lower())
    
    def find_all(self, text: str) -> Dict[str, List[Tuple[str, str]]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ.
        
        Returns:
            Dict –∫–∞—Ç–µ–≥–æ—Ä–∏—è -> List[(–Ω–∞–π–¥–µ–Ω–Ω—ã–π_–ø–∞—Ç—Ç–µ—Ä–Ω, –∫–æ–Ω—Ç–µ–∫—Å—Ç)]
        """
        text_lower = normalize_text(text)
        words = extract_words(text)
        
        results = defaultdict(list)
        
        for category in self.patterns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–∑—ã
            for phrase in self.phrases[category]:
                if phrase in text_lower:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    idx = text_lower.find(phrase)
                    start = max(0, idx - 30)
                    end = min(len(text_lower), idx + len(phrase) + 30)
                    context = text_lower[start:end]
                    results[category].append((phrase, context))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞
            for word in words:
                if word in self.single_words[category]:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ
                    negated = check_negation(text_lower, word)
                    pattern = f"–Ω–µ {word}" if negated else word
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    try:
                        idx = words.index(word)
                        start = max(0, idx - 3)
                        end = min(len(words), idx + 4)
                        context = ' '.join(words[start:end])
                    except:
                        context = word
                    
                    results[category].append((pattern, context))
        
        return dict(results)
    
    def count_by_category(self, text: str) -> Dict[str, int]:
        """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        matches = self.find_all(text)
        return {cat: len(matches) for cat, matches in matches.items()}


class RelationshipAnalyzer:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–Ω–æ—à–µ–Ω–∏–π"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–π
    INSECURITY_PATTERNS = {
        '—Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∞': {
            '—è –Ω–µ –¥–æ—Å—Ç–æ–π–Ω–∞', '—è –Ω–µ –¥–æ—Å—Ç–æ–∏–Ω', '—è –ø–ª–æ—Ö–∞—è', '—è –ø–ª–æ—Ö–æ–π',
            '—è —Ö—É–∂–µ', '—è –Ω–µ–∫—Ä–∞—Å–∏–≤–∞—è', '—è –Ω–µ–∫—Ä–∞—Å–∏–≤—ã–π', '—è —Ç–æ–ª—Å—Ç–∞—è', '—è —Ç–æ–ª—Å—Ç—ã–π',
            '—è –≥–ª—É–ø–∞—è', '—è –≥–ª—É–ø—ã–π', '—è —Ç—É–ø–∞—è', '—è —Ç—É–ø–æ–π',
        },
        '—Å—Ç—Ä–∞—Ö_–æ—Ç–≤–µ—Ä–∂–µ–Ω–∏—è': {
            '—Ç—ã –º–µ–Ω—è –±—Ä–æ—Å–∏—à—å', '—Ç—ã —É–π–¥—ë—à—å', '—Ç—ã –Ω–∞–π–¥—ë—à—å –ª—É—á—à–µ',
            '—è —Ç–µ–±–µ –Ω–∞–¥–æ–µ–ª–∞', '—è —Ç–µ–±–µ –Ω–∞–¥–æ–µ–ª', '—Ç—ã —É—Å—Ç–∞–Ω–µ—à—å –æ—Ç –º–µ–Ω—è',
            '–∑–∞—á–µ–º —è —Ç–µ–±–µ', '–ø–æ—á–µ–º—É —Ç—ã —Å–æ –º–Ω–æ–π',
        },
        '–ø—Ä–æ–≤–µ—Ä–∫–∏': {
            '—Ç—ã –º–µ–Ω—è –ª—é–±–∏—à—å', '—Ç—ã –µ—â—ë –ª—é–±–∏—à—å', '—Ç—ã —Ç–æ—á–Ω–æ –ª—é–±–∏—à—å',
            '—Ç—ã —Å–æ—Å–∫—É—á–∏–ª—Å—è', '—Ç—ã —Å–∫—É—á–∞–ª', '—Ç—ã —Ä–∞–¥ –º–µ–Ω—è –≤–∏–¥–µ—Ç—å',
        },
    }
    
    CONTROL_PATTERNS = {
        '—Å–ª–µ–∂–∫–∞': {
            '–≥–¥–µ —Ç—ã', '—Ç—ã –≥–¥–µ', '—Å –∫–µ–º —Ç—ã', '–∫—Ç–æ —Ç–∞–º', '—á—Ç–æ –¥–µ–ª–∞–µ—à—å',
            '–ø–æ—á–µ–º—É –Ω–µ –æ—Ç–≤–µ—á–∞–µ—à—å', '–ø–æ—á–µ–º—É –¥–æ–ª–≥–æ', '–∫–æ–≥–¥–∞ –≤–µ—Ä–Ω—ë—à—å—Å—è',
        },
        '–∑–∞–ø—Ä–µ—Ç—ã': {
            '–Ω–µ —Ö–æ–¥–∏', '–Ω–µ –æ–±—â–∞–π—Å—è', '–Ω–µ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–π', '—è –∑–∞–ø—Ä–µ—â–∞—é',
            '–Ω–µ–ª—å–∑—è', '–Ω–µ —Ä–∞–∑—Ä–µ—à–∞—é', '–Ω–µ –ø–æ–∑–≤–æ–ª—è—é',
        },
        '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è': {
            '—Ç—ã –¥–æ–ª–∂–µ–Ω', '—Ç—ã –¥–æ–ª–∂–Ω–∞', '—Ç—ã –æ–±—è–∑–∞–Ω', '—Ç—ã –æ–±—è–∑–∞–Ω–∞',
            '–ø–æ–∫–∞–∂–∏ –ø–µ—Ä–µ–ø–∏—Å–∫—É', '–¥–∞–π —Ç–µ–ª–µ—Ñ–æ–Ω', '–æ—Ç–∫—Ä–æ–π –ª–æ–∫–∞—Ü–∏—é',
        },
    }
    
    SUPPORT_PATTERNS = {
        '—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è': {
            '—è —Ä—è–¥–æ–º', '—è —Å —Ç–æ–±–æ–π', '–≤—Å—ë –±—É–¥–µ—Ç —Ö–æ—Ä–æ—à–æ', '—Ç—ã —Å–ø—Ä–∞–≤–∏—à—å—Å—è',
            '–≤–µ—Ä—é –≤ —Ç–µ–±—è', '–≥–æ—Ä–∂—É—Å—å —Ç–æ–±–æ–π', '—Ç—ã –º–æ–ª–æ–¥–µ—Ü',
        },
        '–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è': {
            '–º–æ–≥—É –ø–æ–º–æ—á—å', '—á–µ–º –ø–æ–º–æ—á—å', '–¥–∞–≤–∞–π –ø–æ–º–æ–≥—É', '—Å–¥–µ–ª–∞—é –¥–ª—è —Ç–µ–±—è',
            '—Ä–µ—à—É', '—Ä–∞–∑–±–µ—Ä—É—Å—å', '–Ω–µ –±–µ—Å–ø–æ–∫–æ–π—Å—è',
        },
        '–∏–Ω—Ç–µ—Ä–µ—Å': {
            '–∫–∞–∫ –¥–µ–ª–∞', '–∫–∞–∫ —Ç—ã', '—á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å', '—Ä–∞—Å—Å–∫–∞–∂–∏',
            '–∫–∞–∫ –ø—Ä–æ—à—ë–ª –¥–µ–Ω—å', '–∫–∞–∫ —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å',
        },
    }
    
    def __init__(self):
        self.sentiment = SentimentAnalyzer()
        self.insecurity_matcher = PatternMatcher(self.INSECURITY_PATTERNS)
        self.control_matcher = PatternMatcher(self.CONTROL_PATTERNS)
        self.support_matcher = PatternMatcher(self.SUPPORT_PATTERNS)
    
    def analyze_message(self, text: str) -> Dict:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        sentiment = self.sentiment.analyze(text)
        
        return {
            'sentiment': sentiment,
            'insecurity': self.insecurity_matcher.find_all(text),
            'control': self.control_matcher.find_all(text),
            'support': self.support_matcher.find_all(text),
        }
    
    def analyze_conversation(self, messages: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏"""
        user_stats = defaultdict(lambda: {
            'messages': 0,
            'sentiment_sum': 0.0,
            'sentiment_count': 0,
            'insecurity': defaultdict(int),
            'control': defaultdict(int),
            'support': defaultdict(int),
        })
        
        for msg in messages:
            sender = msg.get('from')
            if not sender:
                continue
            
            text = msg.get('text', '')
            if isinstance(text, list):
                text = ' '.join(
                    p if isinstance(p, str) else p.get('text', '')
                    for p in text
                )
            
            if not text:
                continue
            
            analysis = self.analyze_message(text)
            
            user_stats[sender]['messages'] += 1
            
            if analysis['sentiment']['confidence'] > 0.3:
                user_stats[sender]['sentiment_sum'] += analysis['sentiment']['score']
                user_stats[sender]['sentiment_count'] += 1
            
            for category, matches in analysis['insecurity'].items():
                user_stats[sender]['insecurity'][category] += len(matches)
            
            for category, matches in analysis['control'].items():
                user_stats[sender]['control'][category] += len(matches)
            
            for category, matches in analysis['support'].items():
                user_stats[sender]['support'][category] += len(matches)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for user, stats in user_stats.items():
            if stats['sentiment_count'] > 0:
                stats['avg_sentiment'] = stats['sentiment_sum'] / stats['sentiment_count']
            else:
                stats['avg_sentiment'] = 0.0
        
        return dict(user_stats)

